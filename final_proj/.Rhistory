lift_DT = DT[, .(
model = model_name,
CATE = mean(CATE),
outcome_spend = mean(outcome_spend),
sum_outcome_spend = sum(W==1),
sum_treatment = sum(outcome_spend[W==1]),
N = .N
), keyby = score_group]
return(lift_DT)
}
N_groups = 20
l_test = lift_table("OLS", predict_DT$outcome_spend, predict_DT$CATE_OLS, predict_DT$W, N_groups)
lift_table <- function(model_name, outcome_spend, CATE, W, N_groups = 20) {
DT = data.table(outcome_spend = outcome_spend,
CATE = CATE,
W = W)
DT[, score_group := as.integer(cut_number(CATE, n = N_groups))]
lift_DT = DT[, .(
model = model_name,
CATE = mean(CATE),
outcome_spend = mean(outcome_spend),
sum_outcome_spend = sum(W==1),
sum_treatment = sum(outcome_spend[W==1]),
sum_outcome_spend_nont = sum(W==0),
sum_nontreatment = sum(outcome_spend[W==0]),
N = .N
), keyby = score_group]
return(lift_DT)
}
N_groups = 20
l_test = lift_table("OLS", predict_DT$outcome_spend, predict_DT$CATE_OLS, predict_DT$W, N_groups)
lift_table <- function(model_name, outcome_spend, CATE, W, N_groups = 20) {
DT = data.table(outcome_spend = outcome_spend,
CATE = CATE,
W = W)
DT[, score_group := as.integer(cut_number(CATE, n = N_groups))]
lift_DT = DT[, .(
model = model_name,
CATE = mean(CATE),
outcome_spend = mean(outcome_spend),
sum_outcome_spend = sum(W==1),
sum_treatment = sum(outcome_spend[W==1]),
sum_outcome_spend_nont = sum(W==0),
sum_nontreatment = sum(outcome_spend[W==0]),
ATE = mean(outcome_spend[W == 1], na.rm = TRUE) -
mean(outcome_spend[W == 0], na.rm = TRUE)
), keyby = score_group]
return(lift_DT)
}
N_groups = 20
l_test = lift_table("OLS", predict_DT$outcome_spend, predict_DT$CATE_OLS, predict_DT$W, N_groups)
lift_table <- function(model_name, outcome_spend, CATE, W, N_groups = 20) {
DT = data.table(outcome_spend = outcome_spend,
CATE = CATE,
W = W)
DT[, score_group := as.integer(cut_number(CATE, n = N_groups))]
lift_DT = DT[, .(
model = model_name,
CATE = mean(CATE),
ATE = mean(outcome_spend[W == 1], na.rm = TRUE) -
mean(outcome_spend[W == 0], na.rm = TRUE),
std_error = sqrt(var(outcome_spend[W == 1], na.rm = TRUE)/sum(W == 1) +
var(outcome_spend[W == 0], na.rm = TRUE)/sum(W == 0))
), keyby = score_group]
lift_DT[, `:=`(lower = ATE + qt(0.025, df = N-1)*std_error,
upper = ATE + qt(0.975, df = N-1)*std_error)]
lift_DT[, c("std_error", "N") := NULL]
lift_DT[, lift := 100 * ATE / mean(ATE, na.rm = TRUE)] # Lift based on ATE
return(lift_DT)
}
lifts = list(
lift_table("OLS", predict_DT$outcome_spend, predict_DT$CATE_OLS, predict_DT$W, N_groups),
lift_table("LASSO", predict_DT$outcome_spend, predict_DT$CATE_LASSO, predict_DT$W, N_groups),
lift_table("Elastic net",predict_DT$outcome_spend, predict_DT$CATE_EN, predict_DT$W, N_groups))
N_groups = 20
lifts = list(
lift_table("OLS", predict_DT$outcome_spend, predict_DT$CATE_OLS, predict_DT$W, N_groups),
lift_table("LASSO", predict_DT$outcome_spend, predict_DT$CATE_LASSO, predict_DT$W, N_groups),
lift_table("Elastic net",predict_DT$outcome_spend, predict_DT$CATE_EN, predict_DT$W, N_groups))
N_groups = 20
lifts = list(
lift_table("OLS", predict_DT$outcome_spend, predict_DT$CATE_OLS, predict_DT$W, N_groups),
lift_table("LASSO", predict_DT$outcome_spend, predict_DT$CATE_LASSO, predict_DT$W, N_groups),
lift_table("Elastic net",predict_DT$outcome_spend, predict_DT$CATE_EN, predict_DT$W, N_groups))
N_groups = 20
l_test = lift_table("OLS", predict_DT$outcome_spend, predict_DT$CATE_OLS, predict_DT$W, N_groups)
lift_table <- function(model_name, outcome_spend, CATE, W, N_groups = 20) {
DT = data.table(outcome_spend = outcome_spend,
CATE = CATE,
W = W)
DT[, score_group := as.integer(cut_number(CATE, n = N_groups))]
lift_DT = DT[, .(
model = model_name,
CATE = mean(CATE),
ATE = mean(outcome_spend[W == 1], na.rm = TRUE) -
mean(outcome_spend[W == 0], na.rm = TRUE),
std_error = sqrt(var(outcome_spend[W == 1], na.rm = TRUE)/sum(W == 1) +
var(outcome_spend[W == 0], na.rm = TRUE)/sum(W == 0))
), keyby = score_group]
lift_DT[, `:=`(lower = ATE + qt(0.025, df = N-1)*std_error,
upper = ATE + qt(0.975, df = N-1)*std_error)]
lift_DT[, c("std_error", "N") := NULL]
lift_DT[, lift := 100 * ATE / mean(ATE, na.rm = TRUE)] # Lift based on ATE
return(lift_DT)
}
N_groups = 20
l_test = lift_table("OLS", predict_DT$outcome_spend, predict_DT$CATE_OLS, predict_DT$W, N_groups)
lift_table <- function(model_name, outcome_spend, CATE, W, N_groups = 20) {
DT = data.table(outcome_spend = outcome_spend,
CATE = CATE,
W = W)
DT[, score_group := as.integer(cut_number(CATE, n = N_groups))]
lift_DT = DT[, .(
model = model_name,
CATE = mean(CATE),
ATE = mean(outcome_spend[W == 1], na.rm = TRUE) -
mean(outcome_spend[W == 0], na.rm = TRUE),
std_error = sqrt(var(outcome_spend[W == 1], na.rm = TRUE)/sum(W == 1) +
var(outcome_spend[W == 0], na.rm = TRUE)/sum(W == 0)),
N = .N
), keyby = score_group]
lift_DT[, `:=`(lower = ATE + qt(0.025, df = N-1)*std_error,
upper = ATE + qt(0.975, df = N-1)*std_error)]
lift_DT[, c("std_error", "N") := NULL]
lift_DT[, lift := 100 * ATE / mean(ATE, na.rm = TRUE)] # Lift based on ATE
return(lift_DT)
}
N_groups = 20
lifts = list(
lift_table("OLS", predict_DT$outcome_spend, predict_DT$CATE_OLS, predict_DT$W, N_groups),
lift_table("LASSO", predict_DT$outcome_spend, predict_DT$CATE_LASSO, predict_DT$W, N_groups),
lift_table("Elastic net",predict_DT$outcome_spend, predict_DT$CATE_EN, predict_DT$W, N_groups))
lifts = rbindlist(lifts)
lifts[, model := factor(model, levels = c("OLS", "LASSO", "Elastic net"))]
lifts_print = dcast(lifts, score_group ~ model, value.var = "CATE")
kable(lifts_print, digits = 2)
lifts_print = dcast(lifts, score_group ~ model, value.var = "ATE")
kable(lifts_print, digits = 2)
ggplot(lifts, aes(x = score_group, y = ATE)) +
geom_line(color = "gray70") +
geom_errorbar(aes(ymin = lower, ymax = upper), color = "deepskyblue2",
size = 0.6, width = 0.1) +
geom_point(shape = 21, color = "gray30", fill = "hotpink", size = 2.5) +
scale_x_continuous("Score", limits = c(1, N_groups),
breaks = seq(0, N_groups, 5), minor_breaks = 1:N_groups) +
scale_y_continuous("Treatment effect", limits = c(-5, 20),
breaks = seq(0, 60, 10)) + facet_wrap(~ model, ncol = 2) +
theme_bw()
load(paste0(data_folder, "/Randomized-Implementation-Sample-2018.RData"))
setnames(crm_DT, "mailing_indicator", "W")
# crm_DT is now 2018 data
temp_DT = copy(crm_DT)
# Remove the large_cor_DT$row from crm_DT
temp_DT = temp_DT[, !c(large_cor_DT$row, "customer_id"), with = FALSE]
predict_DT_2018 = crm_DT[, .(customer_id, outcome_spend, W)]
# Predict using OLS
temp_DT[, W := 1]  # Set W = 1 for all data rows
Y_1_OLS = predict(fit_ols, newdata = temp_DT)
temp_DT[, W := 0]  # Set W = 1 for all data rows
Y_0_OLS = predict(fit_ols, newdata = temp_DT)
predict_DT_2018[, CATE_OLS := Y_1_OLS - Y_0_OLS]
# Predict using LASSO
# -> Assume target everyone
temp_DT[, W := 1]  # Set W = 1 for all data rows
Y_1_LASSO <- predict(
fit_LASSO,
newx = model.matrix(outcome_spend ~ W * .,
data = temp_DT)[,-1], s = "lambda.min")
# -> Assume target no one
temp_DT[, W := 0]  # Set W = 0 for all data rows
Y_0_LASSO <- predict(
fit_LASSO,
newx = model.matrix(outcome_spend ~ W * .,
data = temp_DT)[,-1], s = "lambda.min")
predict_DT_2018[, CATE_LASSO := Y_1_LASSO - Y_0_LASSO]
# Predict using Elastic Net
temp_DT[, W := 1]
Y_1_EN <- predict(
fit_elnet,
newx = model.matrix(outcome_spend ~ W * .,
data = temp_DT)[,-1], s = "lambda.min")
temp_DT[, W := 0]  # Set W = 0 for prediction
Y_0_EN <- predict(
fit_elnet,
newx = model.matrix(outcome_spend ~ W * .,
data = temp_DT)[,-1], s = "lambda.min")
predict_DT_2018[, CATE_EN := Y_1_EN - Y_0_EN]
N_groups = 20
lifts = list(
lift_table("OLS", predict_DT_2018$outcome_spend, predict_DT_2018$CATE_OLS,
predict_DT_2018$W, N_groups),
lift_table("LASSO", predict_DT_2018$outcome_spend, predict_DT_2018$CATE_LASSO,
predict_DT_2018$W, N_groups),
lift_table("Elastic net",predict_DT_2018$outcome_spend, predict_DT_2018$CATE_EN,
predict_DT_2018$W, N_groups))
lifts = rbindlist(lifts)
lifts[, model := factor(model, levels = c("OLS", "LASSO", "Elastic net"))]
lifts_print = dcast(lifts, score_group ~ model, value.var = "CATE")
kable(lifts_print, digits = 2)
lifts_print = dcast(lifts, score_group ~ model, value.var = "ATE")
kable(lifts_print, digits = 2)
ggplot(lifts, aes(x = score_group, y = ATE)) +
geom_line(color = "gray70") +
geom_errorbar(aes(ymin = lower, ymax = upper), color = "deepskyblue2",
size = 0.6, width = 0.1) +
geom_point(shape = 21, color = "gray30", fill = "hotpink", size = 2.5) +
scale_x_continuous("Score", limits = c(1, N_groups),
breaks = seq(0, N_groups, 5), minor_breaks = 1:N_groups) +
scale_y_continuous("Theatment Effect", limits = c(-5, 60),
breaks = seq(0, 60, 10)) + facet_wrap(~ model, ncol = 2) +
theme_bw()
# Plot function for lift charts
# Plot function for lift charts with facet_wrap
plot_lift_chart <- function(lift_table) {
ggplot(lift_table, aes(x = score_group)) +
geom_line(aes(y = ATE), color = "blue", linetype = "dashed", size = 1) +
geom_line(aes(y = CATE), color = "red", size = 1) +
geom_text(
aes(x = max(score_group), y = max(ATE), label = "ATE"),
color = "blue", hjust = 1, vjust = 0.5, size = 2
) +
geom_text(
aes(x = max(score_group), y = max(CATE), label = "CATE"),
color = "red", hjust = 1, vjust = 0.5, size = 2
) +
labs(
title = "Lift Chart by Model",
x = "Predicted Spending Group",
y = "Treatment Effect"
) +
facet_wrap(~ model, ncol = 2) +  # Add facet wrap by model
theme_minimal()
}
plot_2_lifts <- plot_lift_chart(lifts)
print(plot_2_lifts)
knitr::opts_chunk$set(echo = TRUE, comment = NA, message = FALSE,
fig.width = 4.5, fig.height = 3.25, fig.align = "right")
knitr::opts_chunk$set(tidy.opts = list(width.cutoff = 60), tidy = TRUE)
knitr::opts_knit$set(root.dir = "/Users/nichada/MyCode/MPCS/_BUSN_DataSci/DataSci_Mkt/final_proj")
setwd("/Users/nichada/MyCode/MPCS/_BUSN_DataSci/DataSci_Mkt/final_proj")
data_folder = "Data"
library(bit64)
library(data.table)
library(glmnet)
library(ggplot2)
library(knitr)
library(corrplot)
library(dplyr)
# Load CATE predictions
predict_DT <- fread("CATE_predict_DT.csv")
load("models.RData")
load("large_cor_DT.RData")
ATE_OLS <- mean(predict_DT$CATE_OLS)
ATE_LASSO <- mean(predict_DT$CATE_LASSO)
ATE_EN <- mean(predict_DT$CATE_EN)
# Print results
cat("ATE (OLS):", ATE_OLS, "\n")
cat("ATE (LASSO):", ATE_LASSO, "\n")
cat("ATE (Elastic Net):", ATE_EN, "\n")
# MSE in each model
mse_OLS = mean((predict_DT$CATE_OLS - ATE_OLS)^2)
mse_LASSO = mean((predict_DT$CATE_LASSO - ATE_LASSO)^2)
mse_elnet = mean((predict_DT$CATE_EN - ATE_EN)^2)
cat(mse_OLS, mse_LASSO, mse_elnet, "\n")
# Combine data for plotting
CATE_melted <- melt(predict_DT[, .(CATE_OLS, CATE_LASSO, CATE_EN)],
variable.name = "Model", value.name = "CATE")
# Plot the distribution of CATEs
ggplot(CATE_melted, aes(x = CATE, fill = Model)) +
geom_density(alpha = 0.5) +
labs(title = "Distribution of Predicted Treatment Effects (CATE)",
x = "CATE", y = "Density") +
theme_minimal()
# Compare scale
# TODO overall mean cate is the same as ate ?
scale_comparison <- predict_DT[, .(
MEAN_CATE_OLS = mean(CATE_OLS),
MIN_CATE_OLS = min(CATE_OLS),
MAX_CATE_OLS = max(CATE_OLS),
MEAN_CATE_LASSO = mean(CATE_LASSO),
MIN_CATE_LASSO = min(CATE_LASSO),
MAX_CATE_LASSO = max(CATE_LASSO),
MEAN_CATE_EN = mean(CATE_EN),
MIN_CATE_EN = min(CATE_EN),
MAX_CATE_EN = max(CATE_EN),
Mean_Sales = mean(outcome_spend)
)]
print(scale_comparison)
# try 2 :
# score_group create
N_groups = 20
predict_DT[, score_group_OLS := as.integer(cut_number(predict_DT$CATE_OLS, n = N_groups))]
predict_DT[, score_group_LASSO := as.integer(cut_number(predict_DT$CATE_LASSO, n = N_groups))]
predict_DT[, score_group_EN := as.integer(cut_number(predict_DT$CATE_EN, n = N_groups))]
# OLS
lift_table_OLS <- function(data, N_groups = 20) {
# Ensure the input data is a data.table
DT <- copy(data)
# Calculate the lift table based on the CATE_OLS column
lift_DT <- DT[, .(
model = "OLS",
CATE = mean(CATE_OLS, na.rm = TRUE),
y = mean(outcome_spend, na.rm = TRUE),
N = .N,
# Calculate standard error for ATE
std_error = sqrt(var(outcome_spend[W == 1], na.rm = TRUE) / sum(W == 1) +
var(outcome_spend[W == 0], na.rm = TRUE) / sum(W == 0)),
treatment_mean = mean(outcome_spend[W == 1], na.rm = TRUE),
nontreatment_mean = mean(outcome_spend[W == 0], na.rm = TRUE),
ATE = mean(outcome_spend[W == 1], na.rm = TRUE) -
mean(outcome_spend[W == 0], na.rm = TRUE)
), keyby = score_group_OLS] # Use score_group_OLS for grouping
# Add confidence intervals for ATE
lift_DT[, `:=`(
lower = ATE + qt(0.025, df = N - 1) * std_error,
upper = ATE + qt(0.975, df = N - 1) * std_error
)]
# Remove unnecessary columns and calculate lift
lift_DT[, c("std_error", "N") := NULL]
lift_DT[, lift := 100 * ATE / mean(ATE, na.rm = TRUE)] # Lift based on ATE
setnames(lift_DT, "score_group_OLS", "score_group")
return(lift_DT)
}
lift_OLS = lift_table_OLS(predict_DT)
# LASSO
lift_table_LASSO <- function(data, N_groups = 20) {
# Ensure the input data is a data.table
DT <- copy(data)
# Calculate the lift table based on the CATE_LASSO column
lift_DT <- DT[, .(
model = "LASSO",
CATE = mean(CATE_LASSO, na.rm = TRUE),
y = mean(outcome_spend, na.rm = TRUE),
N = .N,
# Calculate standard error for ATE
std_error = sqrt(var(outcome_spend[W == 1], na.rm = TRUE) / sum(W == 1) +
var(outcome_spend[W == 0], na.rm = TRUE) / sum(W == 0)),
treatment_mean = mean(outcome_spend[W == 1], na.rm = TRUE),
nontreatment_mean = mean(outcome_spend[W == 0], na.rm = TRUE),
ATE = mean(outcome_spend[W == 1], na.rm = TRUE) -
mean(outcome_spend[W == 0], na.rm = TRUE)
), keyby = score_group_LASSO] # Use score_group_OLS for grouping
# Add confidence intervals for ATE
lift_DT[, `:=`(
lower = ATE + qt(0.025, df = N - 1) * std_error,
upper = ATE + qt(0.975, df = N - 1) * std_error
)]
# Remove unnecessary columns and calculate lift
lift_DT[, c("std_error", "N") := NULL]
lift_DT[, lift := 100 * ATE / mean(ATE, na.rm = TRUE)] # Lift based on ATE
setnames(lift_DT, "score_group_LASSO", "score_group")
return(lift_DT)
}
lift_LASSO = lift_table_LASSO(predict_DT)
# Elastic Net
lift_table_EN <- function(data, N_groups = 20) {
# Ensure the input data is a data.table
DT <- copy(data)
# Calculate the lift table based on the CATE_EN column
lift_DT <- DT[, .(
model = "Elastic",
CATE = mean(CATE_EN, na.rm = TRUE),
y = mean(outcome_spend, na.rm = TRUE),
N = .N,
# Calculate standard error for ATE
std_error = sqrt(var(outcome_spend[W == 1], na.rm = TRUE) / sum(W == 1) +
var(outcome_spend[W == 0], na.rm = TRUE) / sum(W == 0)),
treatment_mean = mean(outcome_spend[W == 1], na.rm = TRUE),
nontreatment_mean = mean(outcome_spend[W == 0], na.rm = TRUE),
ATE = mean(outcome_spend[W == 1], na.rm = TRUE) -
mean(outcome_spend[W == 0], na.rm = TRUE)
), keyby = score_group_EN] # Use score_group_OLS for grouping
# Add confidence intervals for ATE
lift_DT[, `:=`(
lower = ATE + qt(0.025, df = N - 1) * std_error,
upper = ATE + qt(0.975, df = N - 1) * std_error
)]
# Remove unnecessary columns and calculate lift
lift_DT[, c("std_error", "N") := NULL]
lift_DT[, lift := 100 * ATE / mean(ATE, na.rm = TRUE)] # Lift based on ATE
setnames(lift_DT, "score_group_EN", "score_group")
return(lift_DT)
}
lift_EN = lift_table_EN(predict_DT)
# Function to plot lift chart for OLS model
plot_lift_chart_OLS <- function(lift_table) {
ggplot(lift_table, aes(x = score_group)) +
geom_line(aes(y = lift), color = "blue", linetype = "dashed", size = 1) +
geom_line(aes(y = ATE), color = "red", size = 1) +
geom_line(aes(y = CATE), color = "green", size = 1) +
labs(
title = "Lift Chart for OLS Model",
x = "Score Group (OLS)",
y = "Lift / ATE"
) +
scale_x_continuous(breaks = unique(lift_table$score_group_OLS)) +
theme_minimal()
}
plot_lift_chart_OLS(lift_OLS)
plot_lift_chart_OLS(lift_LASSO)
plot_lift_chart_OLS(lift_EN)
combined_ATE <- data.table()
# Select relevant columns and rename ATE to indicate the model
lift_OLS_clean <- lift_OLS[, .(score_group, ATE_OLS = ATE)]
lift_LASSO_clean <- lift_LASSO[, .(score_group, ATE_LASSO = ATE)]
lift_EN_clean <- lift_EN[, .(score_group, ATE_EN = ATE)]
# Combine the ATE columns from all tables into one table by score_group
combined_ATE <- merge(lift_OLS_clean, lift_LASSO_clean, by = "score_group", all = TRUE)
combined_ATE <- merge(combined_ATE, lift_EN_clean, by = "score_group", all = TRUE)
# Display the combined table with kable
kable(combined_ATE, digits = 2, col.names = c("Score Group", "ATE (OLS)", "ATE (LASSO)", "ATE (EN)"))
combined_CATE <- data.table()
# Select relevant columns and rename ATE to indicate the model
lift_OLS_clean <- lift_OLS[, .(score_group, CATE)]
lift_LASSO_clean <- lift_LASSO[, .(score_group, CATE)]
lift_EN_clean <- lift_EN[, .(score_group, CATE)]
# Combine the ATE columns from all tables into one table by score_group
combined_CATE <- merge(lift_OLS_clean, lift_LASSO_clean, by = "score_group", all = TRUE)
combined_CATE <- merge(combined_CATE, lift_EN_clean, by = "score_group", all = TRUE)
# Display the combined table with kable
kable(combined_CATE, digits = 2, col.names = c("Score Group", "CATE (OLS)", "CATE (LASSO)", "CATE (EN)"))
load(paste0(data_folder, "/Randomized-Implementation-Sample-2018.RData"))
setnames(crm_DT, "mailing_indicator", "W")
# crm_DT is now 2018 data
temp_DT = copy(crm_DT)
# Remove the large_cor_DT$row from crm_DT
temp_DT = temp_DT[, !c(large_cor_DT$row, "customer_id"), with = FALSE]
predict_DT_2018 = crm_DT[, .(customer_id, outcome_spend, W)]
# Predict using OLS
temp_DT[, W := 1]  # Set W = 1 for all data rows
Y_1_OLS = predict(fit_ols, newdata = temp_DT)
temp_DT[, W := 0]  # Set W = 1 for all data rows
Y_0_OLS = predict(fit_ols, newdata = temp_DT)
predict_DT_2018[, CATE_OLS := Y_1_OLS - Y_0_OLS]
# Predict using LASSO
# -> Assume target everyone
temp_DT[, W := 1]  # Set W = 1 for all data rows
Y_1_LASSO <- predict(
fit_LASSO,
newx = model.matrix(outcome_spend ~ W * .,
data = temp_DT)[,-1], s = "lambda.min")
# -> Assume target no one
temp_DT[, W := 0]  # Set W = 0 for all data rows
Y_0_LASSO <- predict(
fit_LASSO,
newx = model.matrix(outcome_spend ~ W * .,
data = temp_DT)[,-1], s = "lambda.min")
predict_DT_2018[, CATE_LASSO := Y_1_LASSO - Y_0_LASSO]
# Predict using Elastic Net
temp_DT[, W := 1]
Y_1_EN <- predict(
fit_elnet,
newx = model.matrix(outcome_spend ~ W * .,
data = temp_DT)[,-1], s = "lambda.min")
temp_DT[, W := 0]  # Set W = 0 for prediction
Y_0_EN <- predict(
fit_elnet,
newx = model.matrix(outcome_spend ~ W * .,
data = temp_DT)[,-1], s = "lambda.min")
predict_DT_2018[, CATE_EN := Y_1_EN - Y_0_EN]
# try 2 2018 :
# score_group create
N_groups = 20
predict_DT_2018[, score_group_OLS := as.integer(cut_number(predict_DT_2018$CATE_OLS, n = N_groups))]
predict_DT_2018[, score_group_LASSO := as.integer(cut_number(predict_DT_2018$CATE_LASSO, n = N_groups))]
predict_DT_2018[, score_group_EN := as.integer(cut_number(predict_DT_2018$CATE_EN, n = N_groups))]
lift_OLS_2018 = lift_table_OLS(predict_DT_2018)
lift_LASSO_2018 = lift_table_LASSO(predict_DT_2018)
lift_EN_2018 = lift_table_EN(predict_DT_2018)
plot_lift_chart_OLS(lift_OLS_2018)
plot_lift_chart_OLS(lift_LASSO_2018)
plot_lift_chart_OLS(lift_EN_2018)
# expected result
combined_ATE <- data.table()
# Select relevant columns and rename ATE to indicate the model
lift_OLS_clean <- lift_OLS_2018[, .(score_group, ATE_OLS = ATE)]
lift_LASSO_clean <- lift_LASSO_2018[, .(score_group, ATE_LASSO = ATE)]
lift_EN_clean <- lift_EN_2018[, .(score_group, ATE_EN = ATE)]
# Combine the ATE columns from all tables into one table by score_group
combined_ATE <- merge(lift_OLS_clean, lift_LASSO_clean, by = "score_group", all = TRUE)
combined_ATE <- merge(combined_ATE, lift_EN_clean, by = "score_group", all = TRUE)
# Display the combined table with kable
kable(combined_ATE, digits = 2, col.names = c("Score Group", "ATE (OLS)", "ATE (LASSO)", "ATE (EN)"))
# predicted result
combined_CATE <- data.table()
# Select relevant columns and rename ATE to indicate the model
lift_OLS_clean <- lift_OLS_2018[, .(score_group, CATE)]
lift_LASSO_clean <- lift_LASSO_2018[, .(score_group, CATE)]
lift_EN_clean <- lift_EN_2018[, .(score_group, CATE)]
# Combine the ATE columns from all tables into one table by score_group
combined_CATE <- merge(lift_OLS_clean, lift_LASSO_clean, by = "score_group", all = TRUE)
combined_CATE <- merge(combined_CATE, lift_EN_clean, by = "score_group", all = TRUE)
# Display the combined table with kable
kable(combined_CATE, digits = 2, col.names = c("Score Group", "CATE (OLS)", "CATE (LASSO)", "CATE (EN)"))
margin = 0.325 # 32.5 percent
cost = 0.99 # 99 cents
threshold = cost / margin
# Assuming `predict_DT` contains customer-level CATE predictions
predict_DT_2018[, target := ifelse(CATE_LASSO > threshold, 1, 0)]
# Summarize targeting results
summary_results <- predict_DT_2018[target == 1, .(
total_customers_targeted = .N,
avg_CATE = mean(CATE_LASSO, na.rm = TRUE),
percent_targetted = .N / nrow(predict_DT_2018),
total_cost = .N * cost,
total_profit = sum(CATE_LASSO * margin, na.rm = TRUE)
)]
# Calculate net profit
summary_results[, net_profit := total_profit - total_cost]
# View summary
print(summary_results)
View(predict_DT)
